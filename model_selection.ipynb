{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "import os.path\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the review texts from all files that match the pattern\n",
    "\n",
    "def extract_reviews_data(file_pattern):\n",
    "    data = []\n",
    "    for filename in glob(file_pattern):\n",
    "        with open(filename, \"rb\") as f:\n",
    "            review = f.read().decode(\"utf-8\")\n",
    "            doc_id = filename.split(\"/\")[-1].split(\".\")[0]\n",
    "            data.append({\n",
    "                \"review\": review\n",
    "            })\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the training data with pos and neg reviews\n",
    "train_pos_path = os.path.expanduser(\"~/Desktop/DL4NLT/aclImdb/train/pos/*.txt\")\n",
    "train_neg_path = os.path.expanduser(\"~/Desktop/DL4NLT/aclImdb/train/neg/*.txt\")\n",
    "\n",
    "train_pos_data = extract_reviews_data(train_pos_path)\n",
    "train_neg_data = extract_reviews_data(train_neg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the test data with pos and neg reviews\n",
    "test_pos_path = os.path.expanduser(\"~/Desktop/DL4NLT/aclImdb/test/pos/*.txt\")\n",
    "test_neg_path = os.path.expanduser(\"~/Desktop/DL4NLT/aclImdb/test/neg/*.txt\")\n",
    "\n",
    "test_pos_data = extract_reviews_data(test_pos_path)\n",
    "test_neg_data = extract_reviews_data(test_neg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train.tsv file. positive reviews are labeled as 1 and negative as 0. shuffle data before save to file\n",
    "train_pos_df = pd.DataFrame(train_pos_data)\n",
    "train_pos_df.head()\n",
    "\n",
    "train_pos_df[\"sentiment\"] = 1\n",
    "train_neg_df = pd.DataFrame(train_neg_data)\n",
    "train_neg_df[\"sentiment\"] = 0\n",
    "\n",
    "train_df = pd.concat([train_pos_df, train_neg_df], axis=0)\n",
    "train_df = shuffle(train_df)\n",
    "train_df[\"doc_id\"] = np.arange(len(train_df))\n",
    "\n",
    "train_df[[\"doc_id\", \"sentiment\", \"review\"]].to_csv(\"train.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the test.tsv file. positive reviews are labeled as 1 and negative as 0. shuffle data before save to file\n",
    "test_pos_df = pd.DataFrame(test_pos_data)\n",
    "test_pos_df[\"sentiment\"] = 1\n",
    "test_neg_df = pd.DataFrame(test_neg_data)\n",
    "test_neg_df[\"sentiment\"] = 0\n",
    "\n",
    "test_df = pd.concat([test_pos_df, test_neg_df], axis=0)\n",
    "\n",
    "test_df = shuffle(test_df)\n",
    "test_df[\"doc_id\"] = np.arange(len(test_df))\n",
    "\n",
    "test_df[[\"doc_id\", \"review\"]].to_csv(\"test.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train - test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_df[\"review\"], train_df[\"sentiment\"], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: 20000, Validation: 5000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data: {}, Validation: {}\".format(len(X_train), len(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_features=5000, binary=True, stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit training data\n",
    "vect.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform training and validation data\n",
    "X_train_vect = vect.transform(X_train)\n",
    "X_valid_vect = vect.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = LogisticRegression()\n",
    "model_1.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.964\n",
      "Validation Accuracy: 0.858\n"
     ]
    }
   ],
   "source": [
    "# Training Accuracy\n",
    "print(\"Training Accuracy: {:.3f}\".format(model_1.score(X_train_vect, y_train)))\n",
    "print(\"Validation Accuracy: {:.3f}\".format(model_1.score(X_valid_vect, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = MultinomialNB()\n",
    "model_2.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.864\n",
      "Validation Accuracy: 0.858\n"
     ]
    }
   ],
   "source": [
    "# Training Accuracy\n",
    "print(\"Training Accuracy: {:.3f}\".format(model_2.score(X_train_vect, y_train)))\n",
    "print(\"Validation Accuracy: {:.3f}\".format(model_2.score(X_valid_vect, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = RandomForestClassifier(min_samples_leaf=3, n_estimators=25, n_jobs=-1)\n",
    "model_3.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.948\n",
      "Validation Accuracy: 0.831\n"
     ]
    }
   ],
   "source": [
    "# Training Accuracy\n",
    "print(\"Training Accuracy: {:.3f}\".format(model_3.score(X_train_vect, y_train)))\n",
    "print(\"Validation Accuracy: {:.3f}\".format(model_3.score(X_valid_vect, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4 - Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4 = RandomForestClassifier(min_samples_leaf=3, n_estimators=25, n_jobs=-1)\n",
    "model_4.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.950\n",
      "Validation Accuracy: 0.831\n"
     ]
    }
   ],
   "source": [
    "# Training Accuracy\n",
    "print(\"Training Accuracy: {:.3f}\".format(model_4.score(X_train_vect, y_train)))\n",
    "print(\"Validation Accuracy: {:.3f}\".format(model_4.score(X_valid_vect, y_valid)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [(\"Logistic Regression\", model_1), \n",
    "               (\"Naive Bayes\", model_2), \n",
    "               (\"Random Forest\", model_3), \n",
    "               (\"Gradient Boosted\", model_4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Logistic Regression',\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False)),\n",
       " ('Naive Bayes', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)),\n",
       " ('Random Forest',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=3, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=-1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False)),\n",
       " ('Gradient Boosted',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=3, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=-1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False))]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = VotingClassifier(classifiers, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('Logistic Regression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)..._jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=-1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_model.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.951\n",
      "Validation Accuracy: 0.857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on the ensembled Model\n",
    "print(\"Training Accuracy: {:.3f}\".format(ensemble_model.score(X_train_vect, y_train)))\n",
    "print(\"Validation Accuracy: {:.3f}\".format(ensemble_model.score(X_valid_vect, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the ensembled model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.review\n",
    "X_test_vect = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = ensemble_model.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"doc_id\": test_df.doc_id,\n",
    "    \"sentiment\": y_test_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"ensemlbe_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
